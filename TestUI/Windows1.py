# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'Windows.ui'
#
# Created by: PyQt5 UI code generator 5.15.9
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.
import time
import threading
from playsound import playsound
from moviepy.editor import VideoFileClip
import pyaudio
import wave
from VideoAndSound import VedioAndSound

from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtGui import *
from PyQt5.QtWidgets import *
from PyQt5.QtCore import *
from PyQt5.uic import loadUiType
from libs import *
import sys
from PyQt5.QtCore import QTimer
import numpy as np
import tkinter as tk
from tkinter import filedialog
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)


class AudioStream(threading.Thread):
    def __init__(self):
        super(AudioStream, self).__init__()
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 44100
        self.audio_stream = pyaudio.PyAudio().open(
            format=self.format,
            channels=self.channels,
            rate=self.rate,
            input=True,
            output=True,
            frames_per_buffer=self.chunk
        )
        self.frames = []

    def run(self):
        while True:
            data = self.audio_stream.read(self.chunk)
            self.frames.append(data)

    def get_frames(self):
        return self.frames

class VideoThread(QThread):
    change_pixmap_signal = pyqtSignal(np.ndarray)
    def run(self):
        try:
            print("VideoThread started")
            face_chat = FaceChat()
            print("Facechat instance created")
            audio_stream = AudioStream()
            audio_stream.start()
            face_chat.ReceiveVideo()
            print('VideoThread Finished!')
            for frame in frames:
                self.change_pixmap_signal.emit(frame.flatten())
            #self.change_pixmap_signal.emit(np.zeros((480,640,3), dtype=np.uint8))
        except Exception as e:
            print('Error:' , e)

class ScreenShareThread(QThread):
    change_pixmap_signal = pyqtSignal(np.ndarray)
    def run(self):
        try:
            screen_share=ScreenSharing()
            while True:
                frame=screen_share.Sender()
                self.change_pixmap_signal.emit(frame)
                time.sleep(0.05)
        except Exception as e:
            print('Error:' , e)

class VideoSendThread(QThread):
    change_pixmap_signal = pyqtSignal(np.ndarray)
    def run(self):
        try:
            video_send=SendVedio()
            video_send.SendVideo()
        except Exception as e:
            print('Error:' , e)

class FileTransThread(QThread):
    change_pixmap_signal = pyqtSignal(np.ndarray)
    def run(self):
        try:
            file_send=File()
            file_send.Sender()
        except Exception as e:
            print('Error:' , e)

class FaceChat(object):
    def __init__(self):
        self.chunk = 1024  # 每次读取的音频帧的大小
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 44100
        self.audio_stream = None
        self.sock = None
        self.stop_audio_thread = False

    def init_audio_stream(self):
        p = pyaudio.PyAudio()
        self.audio_stream = p.open(format=self.format,
                                   channels=self.channels,
                                   rate=self.rate,
                                   input=True,
                                   frames_per_buffer=self.chunk)

    def start_audio_thread(self):
        threading.Thread(target=self.send_audio).start()

    def send_audio(self):
        while not self.stop_audio_thread:
            audio_data = self.audio_stream.read(self.chunk)
            self.sock.sendall(audio_data)

    def stop_face_chat(self):
        self.stop_audio_thread = True
        self.audio_stream.stop_stream()
        self.audio_stream.close()
        self.sock.close()

    def SendVideo(self):
        width = 640
        height = 480
        slot_num = 20
        bfsize = int(width * height * 3 / slot_num)
        # 建立sock连接
        # address要连接的服务器IP地址和端口号
        address = ('172.20.10.4', 8002)

        try:
            # 建立socket对象
            # socket.AF_INET：服务器之间网络通信
            # socket.SOCK_STREAM：流式socket , for TCP
            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        # sock = socket.socket(socket.AF_INET,socket.SOCK_STREAM)
        # 开启连接
        # sock.connect(address)
        except socket.error as msg:
            print(msg)
            sys.exit(1)

        self.init_audio_stream()
        self.start_audio_thread()

        # 建立图像读取对象
        capture = cv2.VideoCapture(0)
        # 读取一帧图像，读取成功:ret=1 frame=读取到的一帧图像；读取失败:ret=0
        ret, frame = capture.read()
        # 压缩参数，后面cv2.imencode将会用到，对于jpeg来说，15代表图像质量，越高代表图像质量越好为 0-100，默认95
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 15]

        capture.set(3, 1280)
        capture.set(4, 720)
        # capture.set(cv2.CAP_PROP_FRAME_WIDTH,320)
        # capture.set(cv2.CAP_PROP_FRAME_HEIGHT,240)
        width1 = capture.get(cv2.CAP_PROP_FRAME_WIDTH)
        height1 = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)
        # print("FPS is {}".format(fps))
        print("Width is {}".format(width1))
        print("Height is {}".format(height1))
        # ret= cv2.set(cv2.CAP_PROP_FPS,20.0)
        fps = capture.get(cv2.CAP_PROP_FPS)
        print("FPS is {}".format(fps))

        while ret:
            # 停止0.1S 防止发送过快服务的处理不过来，如果服务端的处理很多，那么应该加大这个值
            time.sleep(0.01)
            ret, frame = capture.read()
            cv2.imshow("sender", frame)
            d = frame.flatten()
            s = d.tostring()
            # sock.sendto(s, address)
            for i in range(20):
                time.sleep(0.001)
                sock.sendto(s[i * bfsize:(i + 1) * bfsize] + str.encode(str(i).zfill(2)), address)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        capture.release()
        cv2.destroyAllWindows()
        sock.close()
        exit(404)

    def ReceiveVideo(self):
        print("ok1")
        width = 640
        height = 480
        slot_num = 200
        bfsize = int(width * height * 3 / slot_num)
        # IP地址'0.0.0.0'为等待客户端连接
        address = ('172.20.10.4', 8002)
        # 建立socket对象
        # socket.AF_INET：服务器之间网络通信
        # socket.SOCK_STREAM：流式socket , for UDP
        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        # 将套接字绑定到地址, 在AF_INET下,以元组（host,port）的形式表示地址.
        sock.bind(address)

        # 开始监听TCP传入连接。参数指定在拒绝连接之前，操作系统可以挂起的最大连接数量。该值至少为1，大部分应用程序设为5就可以了。
        # s.listen(1)

        def recvall(count):
            buf = b''  # buf是一个byte类型
            while count:
                # 接受TCP套接字的数据。数据以字符串形式返回，count指定要接收的最大数据量.
                newbuf = sock.recv(count)
                if not newbuf: return None
                buf += newbuf
                count -= len(newbuf)
            return buf

        # 接受TCP连接并返回（conn,address）,其中conn是新的套接字对象，可以用来接收和发送数据。addr是连接客户端的地址。
        # 没有连接则等待有连接

        # UDP不需要建立连接
        # bfsize = 46080
        chuncksize = bfsize + 2

        frame1 = numpy.zeros(bfsize * 200, dtype=numpy.uint8)
        cnt = 0
        flg = 0
        s = b''
        frames=[]
        while 1:
            print("ok2")
            # start = time.time()#用于计算帧率信息
            cnt += 1
            data, addr = sock.recvfrom(chuncksize)
            i = int(data[-2:].decode())
            line_data = numpy.frombuffer(data[:-2], dtype=numpy.uint8)
            frame1[i * bfsize:(i + 1) * bfsize] = line_data
            frames.append(frame1.copy())
            frames.append(frame1.reshape(height,width,3))
            #print(frame1.shape)
            if cnt == 20:
                # temp_frame = frame1.copy().reshape(480, 640, 3)
                # print(frame1)
                # frame1=frame1*10
                cv2.imshow("receiver frame", frame1[:height * width * 3].reshape(height,width,3))
                cv2.namedWindow("receive frame", cv2.WINDOW_AUTOSIZE)
                cnt = 0
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        print('ok3')
        s.close()
        cv2.destroyAllWindows()

class ScreenSharing:
    # 发送方
    def Sender(self):
        group_ip = '224.0.0.251'
        group_port = 10000
        # 创建IPv4/UDP套接字
        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        # 获取当前分辨率下的屏幕尺寸
        win = tkinter.Tk()
        width = win.winfo_screenwidth()
        height = win.winfo_screenheight()
        # width = win32api.GetSystemMetrics(win32con.SM_CXSCREEN)
        # height = win32api.GetSystemMetrics(win32con.SM_CYSCREEN)
        # 压缩时，大小变为一半
        w = width // 2
        h = height // 2
        while True:
            # 截屏 bbox=None表示截取全屏
            # img = ImageGrab.grab(bbox=None)
            img = ImageGrab.grab(bbox=(0, 0, width, height))
            img.thumbnail((w, h))
            # 图像压缩
            output_buffer = BytesIO()  # 建立二进制对象,在内存中读写
            # RGB格式压缩为JPEG格 式,quality: 保存图像的质量,1(最差)~100
            img.save(output_buffer, format='JPEG', quality=10)
            frame = output_buffer.getvalue()  # 获取二进制数据
            # print(len(frame))
            # 发送文件
            sock.sendto(frame, (group_ip, group_port))
            # sock.send(frame, (group_ip, group_port))
            time.sleep(0.05)  # 加点延时更稳定。
        return frame

    # 接收方
    def Receiver(self):
        group_ip = '224.0.0.251'  # 组地址 239.0.0.1
        group_port = 10000  # 端口号
        # 创建IPv4/UDP套接字
        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        # 获取本地ip 先获取主机名，在通过主机名获取ip
        local_ip = socket.gethostbyname(socket.gethostname())
        #print(local_ip)
        # 绑定端口
        sock.bind((local_ip, group_port))
        # socket.inet_aton  ip转为二进制
        # socket.INADDR_ANY 所有地址
        mreq = struct.pack("=4sl", socket.inet_aton(group_ip), socket.INADDR_ANY)
        # 加入组播组
        # 使用默认的IPV4组播接口
        #print(socket.IPPROTO_IP)
        #print(socket.IP_ADD_MEMBERSHIP)
        sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)
        #print('ok')

        while True:
            plt.clf()  # 清除上一幅图像
            data, addr = sock.recvfrom(655360)  # 接受数值大一点，防止被撑爆
            img = BytesIO(data)
            img = image.imread(img, format='jpeg')
            plt.imshow(img)
            plt.pause(0.05)  # 暂停0.05秒 这一句是实现动态更新的
            plt.ioff()  # 关闭画图的窗口

class SendVedio(object):
    def SendVideo(self):
        width = 640
        height = 368
        slot_num = 20
        address = ('172.20.10.4', 8002)
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        except socket.error as msg:
            print(msg)
            sys.exit(1)
        capture = cv2.VideoCapture(file_address)
        ret, frame = capture.read()
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 15]

        capture.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        capture.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        FPS = capture.set(cv2.CAP_PROP_FPS, 10)
        width1 = capture.get(cv2.CAP_PROP_FRAME_WIDTH)
        height1 = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)
        # print("FPS is {}".format(fps))
        print("Width is {}".format(width1))
        print("Height is {}".format(height1))
        # ret= cv2.set(cv2.CAP_PROP_FPS,20.0)
        fps = capture.get(cv2.CAP_PROP_FPS)
        print("FPS is {}".format(fps))
        bfsize = int(width * height * 3 / slot_num)
        while ret:
            # 停止0.1S 防止发送过快服务的处理不过来，如果服务端的处理很多，那么应该加大这个值
            time.sleep(0.01)
            ret, frame = capture.read()
            cv2.imshow("send frame", frame.reshape(height, width, 3))
            d = frame.flatten()
            s = d.tostring()
            # sock.sendto(s, address)
            for i in range(20):
                time.sleep(0.001)
                sock.sendto(s[i * bfsize:(i + 1) * bfsize] + str.encode(str(i).zfill(2)), address)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        capture.release()
        cv2.destroyAllWindows()
        sock.close();
        exit(404)

    def ReceiveVideo(self):
        width = 640
        height = 368
        slot_num = 20
        # IP地址'0.0.0.0'为等待客户端连接
        address = ('10.24.0.214', 8002)
        # 建立socket对象
        # socket.AF_INET：服务器之间网络通信
        # socket.SOCK_STREAM：流式socket , for UDP
        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        # 将套接字绑定到地址, 在AF_INET下,以元组（host,port）的形式表示地址.
        sock.bind(address)

        # 开始监听TCP传入连接。参数指定在拒绝连接之前，操作系统可以挂起的最大连接数量。该值至少为1，大部分应用程序设为5就可以了。
        # s.listen(1)

        def recvall(count):
            buf = b''  # buf是一个byte类型
            while count:
                # 接受TCP套接字的数据。数据以字符串形式返回，count指定要接收的最大数据量.
                newbuf = sock.recv(count)
                if not newbuf: return None
                buf += newbuf
                count -= len(newbuf)
            return buf

        bfsize = int(width * height * 3 / slot_num)
        chuncksize = bfsize + 2

        frame1 = numpy.zeros(bfsize * slot_num, dtype=numpy.uint8)
        # print(frame1.shape)
        cnt = 0
        flg = 0
        s = b''
        while 1:
            # start = time.time()#用于计算帧率信息
            cnt += 1
            data, addr = sock.recvfrom(chuncksize)
            i = int(data[-2:].decode())
            line_data = numpy.frombuffer(data[:-2], dtype=numpy.uint8)
            frame1[i * bfsize:(i + 1) * bfsize] = line_data
            print(frame1.shape)
            if cnt == 20:
                # temp_frame = frame1.copy().reshape(480, 640, 3)
                # print(frame1)
                cv2.imshow("frame", frame1.reshape(height, width, 3))
                cv2.namedWindow("frame", cv2.WINDOW_AUTOSIZE)
                cnt = 0

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        s.close()
        cv2.destroyAllWindows()

class File(object):
    def Sender(self):
        # 文件发送端
        sk = socket.socket()
        # 定义连接的ip和port
        ip_port = ('172.20.10.4', 9999)
        # 服务器连接
        sk.connect(ip_port)
        root = tk.Tk()
        root.withdraw()

        # 获取文件夹路径
        f_path = filedialog.askopenfilename()
        print('\n获取的文件地址：', f_path)

        with open(f_path, 'rb') as f:
            # 按每一段分割文件上传
            for i in f:
                sk.send(i)
                # 等待接收完成标志
                data = sk.recv(1024)
                # 判断是否真正接收完成
                if data != b'success':
                    break
        # 给服务端发送结束信号
        sk.send('quit'.encode())

    def Receiver(self):
        # 文件接收端
        sk = socket.socket()
        # 定义连接的ip和port
        ip_port = ('172.20.10.4', 9999)
        # 绑定端口
        sk.bind(ip_port)
        # 最大连接数
        sk.listen(5)
        # 进入循环接收数据
        conn, address = sk.accept()
        print("文件接收开始")
        while True:
            with open('file', 'ab') as f:
                # 接收数据
                data = conn.recv(1024)
                if data == b'quit':
                    break
                # 写入文件
                f.write(data)
                # 接受完成标志
                conn.send('success'.encode())
        print("文件接收完成")
        # 关闭连接
        sk.close()

class Ui_MainWindow(object):
    self_VedioTrans=SendVedio
    self_ScreenShare=ScreenSharing
    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(1103, 814)
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")
        self.title = QtWidgets.QTextEdit(self.centralwidget)
        self.title.setGeometry(QtCore.QRect(50, 20, 1001, 41))
        self.title.setLayoutDirection(QtCore.Qt.LeftToRight)
        self.title.setLineWrapMode(QtWidgets.QTextEdit.WidgetWidth)
        self.title.setReadOnly(True)
        self.title.setObjectName("title")
        self.FaceTimeButton = QtWidgets.QPushButton(self.centralwidget)
        self.FaceTimeButton.setGeometry(QtCore.QRect(30, 100, 151, 111))
        self.FaceTimeButton.setContextMenuPolicy(QtCore.Qt.CustomContextMenu)
        self.FaceTimeButton.setIconSize(QtCore.QSize(28, 24))
        self.FaceTimeButton.setObjectName("FaceTimeButton")

        self.VedioTransButton = QtWidgets.QPushButton(self.centralwidget)
        self.VedioTransButton.setGeometry(QtCore.QRect(30, 260, 151, 121))
        self.VedioTransButton.setObjectName("VedioTransButton")
        self.VedioTransButton.clicked.connect(self.start_send_vedio)
        #self.SendVedio_thread.change_pixmap_signal.connect(self.update_image_ScreenShare)

        self.ScreenShareButton = QtWidgets.QPushButton(self.centralwidget)
        self.ScreenShareButton.setGeometry(QtCore.QRect(30, 430, 151, 121))
        self.ScreenShareButton.setObjectName("ScreenShareButton")
        self.ScreenShareButton.clicked.connect(self.start_screen_share)
        self.screenshare_thread=ScreenShareThread()
        self.screenshare_thread.change_pixmap_signal.connect(self.update_image_ScreenShare)
        #self.screenshare_thread.start()

        self.ExitButton = QtWidgets.QToolButton(self.centralwidget)
        self.ExitButton.setGeometry(QtCore.QRect(30, 590, 151, 111))
        self.ExitButton.setObjectName("ExitButton")
        self.DisplayScreen = QtWidgets.QLabel(self.centralwidget)
        self.DisplayScreen.setGeometry(QtCore.QRect(260, 190, 750, 420))
        self.DisplayScreen.setStyleSheet("background-color: rgb(0, 0, 0);")
        self.DisplayScreen.setObjectName("DisplayScreen")
        self.DisplayScreen_2 = QtWidgets.QLabel(self.centralwidget)
        self.DisplayScreen_2.setGeometry(QtCore.QRect(260, 190, 750, 420))
        self.DisplayScreen_2.setStyleSheet("background-color: rgb(0, 0, 0);")
        self.DisplayScreen_2.setObjectName("DisplayScreen_2")
        self.DisplayScreen_2.hide()

        self.SendButton = QtWidgets.QPushButton(self.centralwidget)
        self.SendButton.setGeometry(QtCore.QRect(250, 630, 101, 51))
        self.SendButton.setObjectName("SendButton")
        self.SendButton.clicked.connect(self.sendvedio_thread)

        self.FileTransButton = QtWidgets.QPushButton(self.centralwidget)
        self.FileTransButton.setGeometry(QtCore.QRect(380, 630, 521, 51))
        self.FileTransButton.setObjectName("FileTransButton")
        self.FileTransButton.clicked.connect(self.start_file_trans)
        self.sendfile_thread = FileTransThread()
        self.sendfile_thread.start()

        self.facechat=FaceChat()
        self.FaceTimeButton.clicked.connect(self.start_vedio)
        self.video_thread = VideoThread()
        self.video_thread.change_pixmap_signal.connect(self.update_image_FaceTime)

        self.ExitNowButton = QtWidgets.QToolButton(self.centralwidget)
        self.ExitNowButton.setGeometry(QtCore.QRect(940, 630, 71, 51))
        self.ExitNowButton.setObjectName("ExitNowButton")
        self.ExitNowButton.clicked.connect(self.facechat.stop_face_chat)
        MainWindow.setCentralWidget(self.centralwidget)
        self.menubar = QtWidgets.QMenuBar(MainWindow)
        self.menubar.setGeometry(QtCore.QRect(0, 0, 1103, 30))
        self.menubar.setObjectName("menubar")
        MainWindow.setMenuBar(self.menubar)
        self.statusbar = QtWidgets.QStatusBar(MainWindow)
        self.statusbar.setObjectName("statusbar")
        MainWindow.setStatusBar(self.statusbar)

        self.retranslateUi(MainWindow)
        self.ExitButton.clicked.connect(MainWindow.close) # type: ignore
        self.ExitNowButton.clicked.connect(self.DisplayScreen.clear) # type: ignore
        self.timer_camera = QTimer()
        QtCore.QMetaObject.connectSlotsByName(MainWindow)

    def exit_application(self):
        QCoreApplication.quit()

    def handle_buttons(self):
        self.VedioTransButton.clicked.connect(self.Btn_Start)

    def Btn_Start(self):
        # 定时器开启，每隔一段时间，读取一帧
        self.timer_camera.start(100)
        self.timer_camera.timeout.connect(self.OpenFrame)

    def open_vedio(self):
        # 这里以mp4和avi视频播放为例
        openfile_name = QFileDialog.getOpenFileName(None, 'chose files', '',
                                                        'Image files(*.mp4 *.avi)')  # 打开文件选择框选择文件
        self.file_name = openfile_name[0]  # 获取图片名称
        global file_address
        file_address = os.path.abspath(self.file_name)
        #print(file_address)

        # 得到文件后缀名  需要根据情况进行修改
        suffix = self.file_name.split("/")[-1][self.file_name.split("/")[-1].index(".") + 1:]
        #print(self.file_name, suffix)

        if self.file_name == '':
            pass
        elif suffix == "mp4" or suffix == "avi":
            self.cap = cv2.VideoCapture(self.file_name)

    def OpenFrame(self):
        ret, image = self.cap.read()
        if ret:
            if len(image.shape) == 3:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                vedio_img = QImage(image.data, image.shape[1], image.shape[0], QImage.Format_RGB888)
            elif len(image.shape) == 1:
                vedio_img = QImage(image.data, image.shape[1], image.shape[0], QImage.Format_Indexed8)
            else:
                vedio_img = QImage(image.data, image.shape[1], image.shape[0], QImage.Format_RGB888)

            self.DisplayScreen.setPixmap(QPixmap(vedio_img))
            self.DisplayScreen.setScaledContents(True)  # 自适应窗口
        else:
            self.cap.release()
            self.timer_camera.stop()

    def start_vedio(self):
        self.video_thread.start()

    def start_screen_share(self):
        self.screenshare_thread.start()

    def start_send_vedio(self):
        self.handle_buttons()
        self.open_vedio()
        self.DisplayScreen.show()
        #self.SendVedio_thread=VideoSendThread()
        #self.SendVedio_thread.start()

    def sendvedio_thread(self):
        self.SendVedio_thread = VideoSendThread()
        self.SendVedio_thread.start()

    def start_file_trans(self):
        # 文件上传
        # 打开文件
        # 获取选择文件路径
        root = tk.Tk()
        root.withdraw()

        # 获取文件夹路径
        f_path = filedialog.askopenfilename()
        print('\n获取的文件地址：', f_path)

        with open(f_path, 'rb') as f:
            # 按每一段分割文件上传
            for i in f:
                sk.send(i)
                # 等待接收完成标志
                data = sk.recv(1024)
                # 判断是否真正接收完成
                if data != b'success':
                    break
        sk.send('quit'.encode())

    def update_image_FaceTime(self, frame):
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        height, width, channel = frame.shape
        bytes_per_line = 3 * width
        q_image = QImage(frame.data, width, height, bytes_per_line, QImage.Format_RGB888)
        print('Setting pixmap to DisplayScreen')
        pixmap = QPixmap.fromImage(q_image)
        self.DisplayScreen.setPixmap(pixmap)
        print('Complete Update')


    def update_image_ScreenShare(self, frame):
        image=QImage(frame,frame.shape[1],frame.shape[0],frame.strides[0],QImage.Format_RGB888)
        pixmap=QPixmap.fromImage(image)
        self.DisplayScreen.setPixmap(pixmap)

    def buttonconnect(self,MainWindow):
        '''
        if self.FaceTimeButton.clicked.connect(FaceShow.ReceiveVideo) is True:
            print('Waiting Connect...')
            FaceShow = FaceChat()
            self.DisplayScreen.screen(FaceShow.ReceiveVideo)
            # connect(FaceShow.ReceiveVideo)
            print('Waiting Connect...')
            exit()
        '''

        #if self.VedioTransButton.clicked.connect(SendVedio.ReceiveVideo) is True:
            #self.VedioTransButton.clicked.connect(SendVedio.SendVideo)
        ''''
        self.DisplayScreen = QTimer()
        self.DisplayScreen.start(1000)  # 1000ms == 1s
        self.DisplayScreen.timeout.connect(SendVedio.SendVideo)  # 连接槽函数openFrame
        '''

        ''''
        self.VedioTransButton.clicked.connect(self.self_VedioTrans.SendVideo)
        self.handle_buttons()
        self.open_vedio()
        self.DisplayScreen.show()
        '''

        #self.ScreenShareButton.clicked.connect(self.self_ScreenShare.Receiver)
            #self.DisplayScreen.show(ScreenSharing.Sender)  # type: ignore


    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "MainWindow"))
        self.title.setHtml(_translate("MainWindow", "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0//EN\" \"http://www.w3.org/TR/REC-html40/strict.dtd\">\n"
"<html><head><meta name=\"qrichtext\" content=\"1\" /><style type=\"text/css\">\n"
"p, li { white-space: pre-wrap; }\n"
"</style></head><body style=\" font-family:\'SimSun\'; font-size:9pt; font-weight:400; font-style:normal;\">\n"
"<p align=\"center\" style=\" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;\"><span style=\" font-size:14pt; font-weight:600;\">I AM SENDER</span></p></body></html>"))
        self.FaceTimeButton.setText(_translate("MainWindow", "即时视频通信"))
        self.VedioTransButton.setText(_translate("MainWindow", "本地视频传输"))
        self.ScreenShareButton.setText(_translate("MainWindow", "屏幕共享"))
        self.ExitButton.setText(_translate("MainWindow", "退出当前界面"))
        self.FileTransButton.setText(_translate("MainWindow", "文件传输助手"))
        self.DisplayScreen.setText(_translate("MainWindow", "TextLabel"))
        self.DisplayScreen_2.setText(_translate("MainWindow", "TextLabel"))
        self.ExitNowButton.setText(_translate("MainWindow", "Exit"))
        self.SendButton.setText(_translate("MainWindow", "Send"))


if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    ui = Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()
    ui.buttonconnect(MainWindow)
    sys.exit(app.exec_())

# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'ReceiverWindows.ui'
#
# Created by: PyQt5 UI code generator 5.15.9
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.

import time
import pandas
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtGui import *
from PyQt5.QtWidgets import *
from PyQt5.QtCore import *
from PyQt5.uic import loadUiType
from libs import *
import sys
from PyQt5.QtCore import QTimer
import numpy as np
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

class VideoThread(QThread):
    change_pixmap_signal = pyqtSignal(np.ndarray)
    def run(self):
        try:
            print("VideoThread started")
            face_chat = FaceChat()
            print("Facechat instance created")
            face_chat.SendVideo()
            print('VideoThread Finished!')
            for frame in frames:
                self.change_pixmap_signal.emit(frame.flatten())
            #self.change_pixmap_signal.emit(np.zeros((480,640,3), dtype=np.uint8))
        except Exception as e:
            print('Error:' , e)

class ScreenShareThread(QThread):
    change_pixmap_signal = pyqtSignal(np.ndarray)
    def run(self):
        try:
            screen_share=ScreenSharing()
            print('Enter screen share thread!')
            while True:
                print('Enter while')
                frame = screen_share.Receiver()
                print('Enter frame')
                self.change_pixmap_signal.emit(frame)
                print('Ready to exit')
                time.sleep(0.05)
        except Exception as e:
            print('Error:', e)

class VideoReceiveThread(QThread):
    change_pixmap_signal = pyqtSignal(np.ndarray)
    def run(self):
        try:
            video_receive=ReceiveVedio()
            video_receive.ReceiveVideo()
        except Exception as e:
            print('Error:' , e)

class FaceChat(object):
    def SendVideo(self):
        width = 640
        height = 480
        slot_num = 20
        bfsize = int(width * height * 3 / slot_num)
        # 建立sock连接
        # address要连接的服务器IP地址和端口号
        address = ('172.20.10.4', 8002)

        try:
            # 建立socket对象
            # socket.AF_INET：服务器之间网络通信
            # socket.SOCK_STREAM：流式socket , for TCP
            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        # sock = socket.socket(socket.AF_INET,socket.SOCK_STREAM)
        # 开启连接
        # sock.connect(address)
        except socket.error as msg:
            print(msg)
            sys.exit(1)

        # 建立图像读取对象
        capture = cv2.VideoCapture(0)
        # 读取一帧图像，读取成功:ret=1 frame=读取到的一帧图像；读取失败:ret=0
        ret, frame = capture.read()
        # 压缩参数，后面cv2.imencode将会用到，对于jpeg来说，15代表图像质量，越高代表图像质量越好为 0-100，默认95
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 15]

        capture.set(3, 1280)
        capture.set(4, 720)
        # capture.set(cv2.CAP_PROP_FRAME_WIDTH,320)
        # capture.set(cv2.CAP_PROP_FRAME_HEIGHT,240)
        width1 = capture.get(cv2.CAP_PROP_FRAME_WIDTH)
        height1 = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)
        # print("FPS is {}".format(fps))
        print("Width is {}".format(width1))
        print("Height is {}".format(height1))
        # ret= cv2.set(cv2.CAP_PROP_FPS,20.0)
        fps = capture.get(cv2.CAP_PROP_FPS)
        print("FPS is {}".format(fps))

        while ret:
            # 停止0.1S 防止发送过快服务的处理不过来，如果服务端的处理很多，那么应该加大这个值
            time.sleep(0.01)
            ret, frame = capture.read()
            cv2.imshow("sender", frame)
            d = frame.flatten()
            s = d.tostring()
            # sock.sendto(s, address)
            for i in range(20):
                time.sleep(0.001)
                sock.sendto(s[i * bfsize:(i + 1) * bfsize] + str.encode(str(i).zfill(2)), address)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        capture.release()
        cv2.destroyAllWindows()
        sock.close()
        exit(404)

    def ReceiveVideo(self):
        print("ok1")
        width = 640
        height = 480
        slot_num = 200
        bfsize = int(width * height * 3 / slot_num)
        # IP地址'0.0.0.0'为等待客户端连接
        address = ('172.20.10.4', 8002)
        # 建立socket对象
        # socket.AF_INET：服务器之间网络通信
        # socket.SOCK_STREAM：流式socket , for UDP
        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        # 将套接字绑定到地址, 在AF_INET下,以元组（host,port）的形式表示地址.
        sock.bind(address)

        # 开始监听TCP传入连接。参数指定在拒绝连接之前，操作系统可以挂起的最大连接数量。该值至少为1，大部分应用程序设为5就可以了。
        # s.listen(1)

        def recvall(count):
            buf = b''  # buf是一个byte类型
            while count:
                # 接受TCP套接字的数据。数据以字符串形式返回，count指定要接收的最大数据量.
                newbuf = sock.recv(count)
                if not newbuf: return None
                buf += newbuf
                count -= len(newbuf)
            return buf

        # 接受TCP连接并返回（conn,address）,其中conn是新的套接字对象，可以用来接收和发送数据。addr是连接客户端的地址。
        # 没有连接则等待有连接

        # UDP不需要建立连接
        # bfsize = 46080
        chuncksize = bfsize + 2

        frame1 = numpy.zeros(bfsize * 200, dtype=numpy.uint8)
        cnt = 0
        flg = 0
        s = b''
        frames=[]
        while 1:
            print("ok2")
            # start = time.time()#用于计算帧率信息
            cnt += 1
            data, addr = sock.recvfrom(chuncksize)
            i = int(data[-2:].decode())
            line_data = numpy.frombuffer(data[:-2], dtype=numpy.uint8)
            frame1[i * bfsize:(i + 1) * bfsize] = line_data
            frames.append(frame1.copy())
            frames.append(frame1.reshape(height,width,3))
            #print(frame1.shape)
            if cnt == 20:
                # temp_frame = frame1.copy().reshape(480, 640, 3)
                # print(frame1)
                # frame1=frame1*10
                cv2.imshow("receiver frame", frame1[:height * width * 3].reshape(height,width,3))
                cv2.namedWindow("receive frame", cv2.WINDOW_AUTOSIZE)
                cnt = 0
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        print('ok3')
        s.close()
        cv2.destroyAllWindows()

class ScreenSharing:
    # 发送方
    def Sender(self):
        group_ip = '224.0.0.251'
        group_port = 10000
        # 创建IPv4/UDP套接字
        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        # 获取当前分辨率下的屏幕尺寸
        win = tkinter.Tk()
        width = win.winfo_screenwidth()
        height = win.winfo_screenheight()
        # width = win32api.GetSystemMetrics(win32con.SM_CXSCREEN)
        # height = win32api.GetSystemMetrics(win32con.SM_CYSCREEN)
        # 压缩时，大小变为一半
        w = width // 2
        h = height // 2
        while True:
            # 截屏 bbox=None表示截取全屏
            # img = ImageGrab.grab(bbox=None)
            img = ImageGrab.grab(bbox=(0, 0, width, height))
            img.thumbnail((w, h))
            # 图像压缩
            output_buffer = BytesIO()  # 建立二进制对象,在内存中读写
            # RGB格式压缩为JPEG格 式,quality: 保存图像的质量,1(最差)~100
            img.save(output_buffer, format='JPEG', quality=10)
            frame = output_buffer.getvalue()  # 获取二进制数据
            # print(len(frame))
            # 发送文件
            sock.sendto(frame, (group_ip, group_port))
            # sock.send(frame, (group_ip, group_port))
            time.sleep(0.05)  # 加点延时更稳定。

    # 接收方
    def Receiver(self):
        group_ip = '224.0.0.251'  # 组地址 239.0.0.1
        group_port = 10000  # 端口号
        # 创建IPv4/UDP套接字
        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        # 获取本地ip 先获取主机名，在通过主机名获取ip
        local_ip = socket.gethostbyname(socket.gethostname())
        #print(local_ip)
        # 绑定端口
        sock.bind((local_ip, group_port))
        # socket.inet_aton  ip转为二进制
        # socket.INADDR_ANY 所有地址
        mreq = struct.pack("=4sl", socket.inet_aton(group_ip), socket.INADDR_ANY)
        # 加入组播组
        # 使用默认的IPV4组播接口
        #print(socket.IPPROTO_IP)
        #print(socket.IP_ADD_MEMBERSHIP)
        sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)
        #print('ok')

        while True:
            frame=[]
            print('ok1')
            plt.clf()  # 清除上一幅图像
            print('ok2')
            data, addr = sock.recvfrom(655360)  # 接受数值大一点，防止被撑爆
            #global img
            img = BytesIO(data)
            img = image.imread(img, format='jpeg')
            #img = (img*255).astype(np.uint8)
            frame.append(img)
            plt.imshow(img)
            plt.pause(0.05)  # 暂停0.05秒 这一句是实现动态更新的
            plt.ioff()  # 关闭画图的窗口
            print('ok3')
            frame.append(img)
        return frame

class ReceiveVedio(object):
    def SendVideo(self):
        width = 640
        height = 368
        slot_num = 20
        # 建立sock连接
        # address要连接的服务器IP地址和端口号
        address = ('172.20.10.4', 8002)
        # address = ('10.18.96.207', 8002)
        try:
            # 建立socket对象
            # socket.AF_INET：服务器之间网络通信
            # socket.SOCK_STREAM：流式socket , for TCP
            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        # sock = socket.socket(socket.AF_INET,socket.SOCK_STREAM)
        # 开启连接
        # sock.connect(address)
        except socket.error as msg:
            print(msg)
            sys.exit(1)

        # 建立图像读取对象
        capture = cv2.VideoCapture(file_address)
        #capture = cv2.VideoCapture('3.mp4')
        # 读取一帧图像，读取成功:ret=1 frame=读取到的一帧图像；读取失败:ret=0
        ret, frame = capture.read()
        # 压缩参数，后面cv2.imencode将会用到，对于jpeg来说，15代表图像质量，越高代表图像质量越好为 0-100，默认95
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 15]

        capture.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        capture.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        FPS = capture.set(cv2.CAP_PROP_FPS, 10)
        width1 = capture.get(cv2.CAP_PROP_FRAME_WIDTH)
        height1 = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)
        # print("FPS is {}".format(fps))
        print("Width is {}".format(width1))
        print("Height is {}".format(height1))
        # ret= cv2.set(cv2.CAP_PROP_FPS,20.0)
        fps = capture.get(cv2.CAP_PROP_FPS)
        print("FPS is {}".format(fps))
        bfsize = int(width * height * 3 / slot_num)
        while ret:
            # 停止0.1S 防止发送过快服务的处理不过来，如果服务端的处理很多，那么应该加大这个值
            time.sleep(0.01)
            ret, frame = capture.read()
            cv2.imshow("send frame", frame.reshape(height, width, 3))
            d = frame.flatten()
            s = d.tostring()
            # sock.sendto(s, address)
            for i in range(20):
                # print(len(s[i*46080:(i+1)*46080]))
                # print(len(str.encode(str(i).zfill(2))))
                # print(s[i*46080:(i+1)*46080])
                # print(str.encode(str(i).zfill(2)))
                time.sleep(0.001)
                sock.sendto(s[i * bfsize:(i + 1) * bfsize] + str.encode(str(i).zfill(2)), address)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        capture.release()
        cv2.destroyAllWindows()
        sock.close();
        exit(404)

    def ReceiveVideo(self):
        width = 640
        height = 368
        slot_num = 20
        # IP地址'0.0.0.0'为等待客户端连接
        address = ('172.20.10.4', 8002)
        # 建立socket对象
        # socket.AF_INET：服务器之间网络通信
        # socket.SOCK_STREAM：流式socket , for UDP
        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        # 将套接字绑定到地址, 在AF_INET下,以元组（host,port）的形式表示地址.
        sock.bind(address)

        # 开始监听TCP传入连接。参数指定在拒绝连接之前，操作系统可以挂起的最大连接数量。该值至少为1，大部分应用程序设为5就可以了。
        # s.listen(1)

        def recvall(count):
            buf = b''  # buf是一个byte类型
            while count:
                # 接受TCP套接字的数据。数据以字符串形式返回，count指定要接收的最大数据量.
                newbuf = sock.recv(count)
                if not newbuf: return None
                buf += newbuf
                count -= len(newbuf)
            return buf

        bfsize = int(width * height * 3 / slot_num)
        chuncksize = bfsize + 2

        frame1 = numpy.zeros(bfsize * slot_num, dtype=numpy.uint8)
        # print(frame1.shape)
        cnt = 0
        flg = 0
        s = b''
        while 1:
            # start = time.time()#用于计算帧率信息
            cnt += 1
            data, addr = sock.recvfrom(chuncksize)
            i = int(data[-2:].decode())
            line_data = numpy.frombuffer(data[:-2], dtype=numpy.uint8)
            frame1[i * bfsize:(i + 1) * bfsize] = line_data
            print(frame1.shape)
            if cnt == 20:
                # temp_frame = frame1.copy().reshape(480, 640, 3)
                # print(frame1)
                cv2.imshow("frame", frame1.reshape(height, width, 3))
                cv2.namedWindow("frame", cv2.WINDOW_AUTOSIZE)
                cnt = 0

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        s.close()
        cv2.destroyAllWindows()


class Ui_MainWindow(object):
    screenshare_connect=ScreenSharing
    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(1114, 815)
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")
        self.title = QtWidgets.QTextEdit(self.centralwidget)
        self.title.setGeometry(QtCore.QRect(70, 30, 1001, 41))
        self.title.setLayoutDirection(QtCore.Qt.LeftToRight)
        self.title.setLineWrapMode(QtWidgets.QTextEdit.WidgetWidth)
        self.title.setReadOnly(True)
        self.title.setObjectName("title")
        self.DisplayScreen = QtWidgets.QLabel(self.centralwidget)
        self.DisplayScreen.setGeometry(QtCore.QRect(280, 200, 750, 420))
        self.DisplayScreen.setStyleSheet("background-color: rgb(0, 0, 0);")
        self.DisplayScreen.setObjectName("DisplayScreen")
        self.FaceTimeButton = QtWidgets.QPushButton(self.centralwidget)
        self.FaceTimeButton.setGeometry(QtCore.QRect(50, 110, 151, 111))
        self.FaceTimeButton.setContextMenuPolicy(QtCore.Qt.CustomContextMenu)
        self.FaceTimeButton.setIconSize(QtCore.QSize(28, 24))
        self.FaceTimeButton.setObjectName("FaceTimeButton")
        self.FaceTimeButton.clicked.connect(self.start_vedio)
        self.video_thread = VideoThread()
        self.video_thread.change_pixmap_signal.connect(self.update_image_FaceTime)

        self.ScreenShareButton = QtWidgets.QPushButton(self.centralwidget)
        self.ScreenShareButton.setGeometry(QtCore.QRect(50, 440, 151, 121))
        self.ScreenShareButton.setObjectName("ScreenShareButton")
        self.ScreenShareButton.clicked.connect(self.screenshare_connect.Receiver)
        #self.screenshare_thread = ScreenShareThread()
        #self.screenshare_thread.change_pixmap_signal.connect(self.update_image_ScreenShare)

        self.VedioTransButton = QtWidgets.QPushButton(self.centralwidget)
        self.VedioTransButton.setGeometry(QtCore.QRect(50, 270, 151, 121))
        self.VedioTransButton.setObjectName("VedioTransButton")
        self.VedioTransButton.clicked.connect(self.start_receive_vedio)

        self.FileTransButton = QtWidgets.QPushButton(self.centralwidget)
        self.FileTransButton.setGeometry(QtCore.QRect(400, 640, 521, 51))
        self.FileTransButton.setObjectName("FileTransButton")

        self.DisplayScreen_2 = QtWidgets.QLabel(self.centralwidget)
        self.DisplayScreen_2.setGeometry(QtCore.QRect(280, 200, 750, 420))
        self.DisplayScreen_2.setStyleSheet("background-color: rgb(0, 0, 0);")
        self.DisplayScreen_2.setObjectName("DisplayScreen_2")
        self.ExitNowButton = QtWidgets.QToolButton(self.centralwidget)
        self.ExitNowButton.setGeometry(QtCore.QRect(960, 640, 71, 51))
        self.ExitNowButton.setObjectName("ExitNowButton")
        self.ExitButton = QtWidgets.QToolButton(self.centralwidget)
        self.ExitButton.setGeometry(QtCore.QRect(50, 600, 151, 111))
        self.ExitButton.setObjectName("ExitButton")

        ''''
        self.timer_camera = QTimer()
        self.timer = QTimer(MainWindow)
        self.timer.timeout.connect(self.update_image_ScreenShare)
        self.timer.start(50)
        '''

        MainWindow.setCentralWidget(self.centralwidget)
        self.menubar = QtWidgets.QMenuBar(MainWindow)
        self.menubar.setGeometry(QtCore.QRect(0, 0, 1114, 30))
        self.menubar.setObjectName("menubar")
        MainWindow.setMenuBar(self.menubar)
        self.statusbar = QtWidgets.QStatusBar(MainWindow)
        self.statusbar.setObjectName("statusbar")
        MainWindow.setStatusBar(self.statusbar)

        self.retranslateUi(MainWindow)
        self.ExitButton.clicked.connect(MainWindow.close) # type: ignore
        QtCore.QMetaObject.connectSlotsByName(MainWindow)

    def start_vedio(self):
        self.video_thread.start()

    def start_screen_share(self):
        self.screenshare_thread.start()
        print('start screen share')

    def start_receive_vedio(self):
        #self.handle_buttons()
        #self.open_vedio()
        self.DisplayScreen.show()
        self.ReceiveVedio_thread=VideoReceiveThread()
        self.ReceiveVedio_thread.start()

    def update_image_FaceTime(self, frame):
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        height, width, channel = frame.shape
        bytes_per_line = 3 * width
        q_image = QImage(frame.data, width, height, bytes_per_line, QImage.Format_RGB888)
        print('Setting pixmap to DisplayScreen')
        pixmap = QPixmap.fromImage(q_image)
        self.DisplayScreen.setPixmap(pixmap)
        print('Complete Update')

    def update_image_ScreenShare(self, frame):#在主线程中更新GUI
        pixmap=self.convert_frame_to_pixmap(frame)
        self.DisplayScreen.setPixmap(pixmap)
        #QCoreApplication.instance().processEvents

    def convert_frame_to_pixmap(self,frame):   #将帧转换为QPixmap
        image = QImage(frame, frame.shape[1], frame.shape[0], frame.strides[0], QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(image)
        self.DisplayScreen.setPixmap(pixmap)


    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "MainWindow"))
        self.title.setHtml(_translate("MainWindow", "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0//EN\" \"http://www.w3.org/TR/REC-html40/strict.dtd\">\n"
"<html><head><meta name=\"qrichtext\" content=\"1\" /><style type=\"text/css\">\n"
"p, li { white-space: pre-wrap; }\n"
"</style></head><body style=\" font-family:\'SimSun\'; font-size:9pt; font-weight:400; font-style:normal;\">\n"
"<p align=\"center\" style=\" margin-top:0px; margin-bottom:0px; margin-left:0px; margin-right:0px; -qt-block-indent:0; text-indent:0px;\"><span style=\" font-size:14pt; font-weight:600;\">I AM RECEIVER</span></p></body></html>"))
        self.DisplayScreen.setText(_translate("MainWindow", "TextLabel"))
        self.FaceTimeButton.setText(_translate("MainWindow", "即时视频通信"))
        self.ScreenShareButton.setText(_translate("MainWindow", "屏幕共享"))
        self.VedioTransButton.setText(_translate("MainWindow", "本地视频传输"))
        self.DisplayScreen_2.setText(_translate("MainWindow", "TextLabel"))
        self.ExitNowButton.setText(_translate("MainWindow", "Exit"))
        self.ExitButton.setText(_translate("MainWindow", "退出当前界面"))
        self.FileTransButton.setText(_translate("MainWindow", "文件传输助手"))


if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    ui = Ui_MainWindow()
    ui.setupUi(MainWindow)
    MainWindow.show()
    sys.exit(app.exec_())
